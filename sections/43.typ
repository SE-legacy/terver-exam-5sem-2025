#import "../conf.typ": *

Пусть 
$(X_t, Y_t), t = overline(1"," n)$ ---
результат наблюдений. Предположим, что $Y = f(X)$, тогда в результате наблюдений, значения $Y_t$ измерены с ошибкой, т.е. 
$Y_t = f(X_t) + epsilon_t$.
Пусть $f(x)$ --- линейная функция. Тогда 
$Y_t = a + b X_t + epsilon_t, space t = overline(1"," n), space Y_t$ ---
зависимая переменная (объясняемая), $X_t$ --- независимая (регрессор), $epsilon_t$ --- случайная величина (случайная ошибка)

+ Спецификация регрессионной модели
  $Y_t = a + b X_t + epsilon_t, space t = overline(1"," n)$
+ $X_t$ --- детерминированная величина
+ $M epsilon_t = 0, space M epsilon^2_t = D epsilon_t = sigma^2$ --- не зависит от $t$\
  $M epsilon_t epsilon_s = 0, space s != t$ (некоррелированность ошибок модели)
+ $epsilon_t ~ cal(N)(0; sigma^2)$ --- нормальная модель

*Теорема Гаусса-Маркова*: в предположениях 1, 2, 3 оценки $accent(a, \^)$ и $accent(b, \^)$, полученные МНК, имеют наименьшую дисперсию в классе несмещенных оценок.